{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4820c3e-d01f-40e4-b1ae-2fbfcbedc1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwartlab-users\\.conda\\envs\\neuroviewer\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "\n",
    "import napari_plot\n",
    "from napari_plot._qt.qt_viewer import QtViewer\n",
    "from dask_image.imread import imread\n",
    "from magicgui.widgets import ComboBox, Container, PushButton, SpinBox, FileEdit, FloatSpinBox, Label, TextEdit\n",
    "\n",
    "from dask_image import imread\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import os\n",
    "from napari.qt.threading import thread_worker\n",
    "\n",
    "from dipy.align.imaffine import AffineMap\n",
    "from numba import jit\n",
    "import tifffile as tf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "326edfc5-d3b9-4db1-bf9f-3e158f83ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuro_viewer(object):\n",
    "    \n",
    "    im = None\n",
    "    denoised_dir = None\n",
    "    volume_df = None\n",
    "    coms_df = None\n",
    "    con_df = None\n",
    "    dff_tidy = None\n",
    "    \n",
    "    \n",
    "    def __init__(self, fr = 3.07):\n",
    "        \n",
    "        \n",
    "\n",
    "        self.viewer = napari.Viewer()\n",
    "        self.viewer.add_image(np.zeros((512, 512)), name = \"deconvolved\", opacity = 0.5)\n",
    "        self.im_subset = self.viewer.layers[0]\n",
    "        self.im_subset.colormap = \"inferno\"\n",
    "        \n",
    "        self.viewer.add_image(np.zeros((512, 512)), name = \"overview\", opacity = 0.5)\n",
    "        self.overview_im = self.viewer.layers[1]\n",
    "        self.overview_im.colormap = \"cyan\"\n",
    "        \n",
    "        self.viewer.add_image(np.zeros((512, 512)), name = \"reference\", opacity = 0.5)\n",
    "        self.reference_brain = self.viewer.layers[2]\n",
    "        \n",
    "        self.viewer.add_image(np.zeros((512, 512)), name = \"template\", opacity = 0.5)\n",
    "        self.template = self.viewer.layers[3]\n",
    "        self.template.colormap = \"magenta\"\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        self.stim_icon = self.viewer.add_shapes(np.array([[0, 0, 0],\n",
    "                                                           [0, 0, 0],\n",
    "                                                           [0, 0, 0],\n",
    "                                                           [0, 0, 0]]), shape_type='rectangle', edge_width=5,\n",
    "                                                            edge_color='#55ff00', face_color = \"#55ff00\", name = \"stim\")\n",
    "        #self.all_rois = self.viewer.add_shapes(shape_type = \"polygon\", edge_width=0.2,\n",
    "        #                  edge_color='white', face_color='transparent', ndim = 4)\n",
    "        self.select_roi = self.viewer.add_shapes(shape_type='polygon', edge_width=0.2,\n",
    "                          edge_color='white', face_color='transparent', ndim = 4, name = \"rois\")\n",
    "        \n",
    "        self.im_subset.contrast_limits = (0, 255)\n",
    "        self.overview_im.contrast_limits = (0, 10000)\n",
    "        self.fr = fr\n",
    "        \n",
    "        \n",
    "        # create label menus for stim, trial, angle, velocity\n",
    "        #update choices as required when stim is changed\n",
    "        self.stim_menu = ComboBox(label='Stim', choices = [\"visual\", \"motion\", \"flow\"], tooltip = \"Select stim\")\n",
    "        self.trial_menu = ComboBox(label='Trial', choices = [], tooltip = \"Select stim\")\n",
    "        self.angle_menu = ComboBox(label='Angle', choices = [], tooltip = \"Select stim\")\n",
    "        self.velocity_menu = ComboBox(label='Velocity', choices = [], tooltip = \"Select stim\")\n",
    "        \n",
    "        \n",
    "        dropdown_widget = Container(widgets=[self.stim_menu, self.trial_menu, self.angle_menu, self.velocity_menu])\n",
    "        \n",
    "        \n",
    "        self.stim_menu.changed.connect(self.stim_changed)\n",
    "        self.trial_menu.changed.connect(self.trial_changed)\n",
    "        self.angle_menu.changed.connect(self.angle_changed)\n",
    "        self.velocity_menu.changed.connect(self.velocity_changed)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cell_ids = SpinBox(label = \"cell_id\", tooltip = \"change cell\")\n",
    "        cell_widget = Container(widgets=[self.cell_ids])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.volume_df_picker= FileEdit(value='./Select volume_df.h5', tooltip = \"Select volume_df\")\n",
    "        file_widget = Container(widgets=[self.volume_df_picker])\n",
    "        \n",
    "        \n",
    "        registration_label = Label(name = \"Registration\", label = \"Registration\")\n",
    "        self.moving_im_file = FileEdit(value='./Select image to register', tooltip = \"Select template tif\")\n",
    "        self.reference_im_file = FileEdit(value='./Select reference image', tooltip = \"Select reference tif\")\n",
    "                                   \n",
    "        self.translate_x = FloatSpinBox(label = \"translate x\", tooltip = \"change x translation\", min = -500, max = 500, value = 0)\n",
    "        self.translate_y = FloatSpinBox(label = \"translate y\", tooltip = \"change y translation\", min = -500, max = 500, value = 0)\n",
    "        self.translate_z = FloatSpinBox(label = \"translate z\", tooltip = \"change z translation\", min = -500, max = 500, value = 0)\n",
    "        self.affine_name = TextEdit(label = \"affine filename\", value = \"affine.npy\")\n",
    "        self.save_affine_button = PushButton(label = \"save affine\")\n",
    "        \n",
    "        self.translate_x.changed.connect(self.translate)\n",
    "        self.translate_y.changed.connect(self.translate)\n",
    "        self.translate_z.changed.connect(self.translate)\n",
    "        self.save_affine_button.clicked.connect(self.save_starting_affine)\n",
    "        \n",
    "        self.moving_im_file.changed.connect(self.read_moving_im)\n",
    "        self.reference_im_file.changed.connect(self.read_reference_im)\n",
    "        \n",
    "        translation_widget = Container(widgets=[registration_label,\n",
    "                                                self.moving_im_file, self.reference_im_file,\n",
    "                                                self.translate_x, self.translate_y, self.translate_z, \n",
    "                                                self.affine_name, self.save_affine_button])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.volume_df_picker.changed.connect(self.volume_df_picker_changed)\n",
    "        self.viewer.window.add_dock_widget(dropdown_widget)\n",
    "        self.viewer.window.add_dock_widget(cell_widget)\n",
    "        self.viewer.window.add_dock_widget(file_widget)\n",
    "        self.viewer.window.add_dock_widget(translation_widget)\n",
    "        self.add_dff_widget()\n",
    "        self.add_ephys_widget()\n",
    "        self.cell = self.cell_ids.value\n",
    "        self.cell_ids.changed.connect(self.plot_cell)\n",
    "        self.select_roi.events.highlight.connect(self.roi_selected)\n",
    "        \n",
    "        self.io_affine = None\n",
    "        self.grid_copy = None\n",
    "        \n",
    "        \n",
    "      \n",
    "    def load_image(self):\n",
    "        \"\"\"Load image\"\"\"\n",
    "        if self.volume_subset.shape[0] > 0:\n",
    "            print(\"loading dask images\")\n",
    "            self.im_subset.data = self.im[:, self.first_vol:self.end_vol ].compute()\n",
    "            print(\"images loaded\")\n",
    "            \n",
    "        else:\n",
    "            print(\"no volumes\")\n",
    "        pass\n",
    "    \n",
    "    def load_volume_df(self, path):\n",
    "        \"\"\"Load pandas dataframe containing all information about volume\"\"\"\n",
    "        print(\"loading volume_df\")\n",
    "        self.volume_df = pd.read_hdf(path)\n",
    "        \n",
    "    def load_coms_df(self, path):\n",
    "        print(\"loading coms_df\")\n",
    "        self.coms_df = pd.read_hdf(path)\n",
    "        \n",
    "    \n",
    "    def load_con_df(self, path):\n",
    "        print(\"loading con_df\")\n",
    "        self.con_df = pd.read_hdf(path)\n",
    "        self.plot_all_contours()\n",
    "        \n",
    "    def load_dff_df(self, path):\n",
    "        \"\"\"Load all dff data\"\"\"\n",
    "        print(\"loading dff_df\")\n",
    "        self.dff_tidy = pd.read_hdf(path, \"df\")\n",
    "    \n",
    "    \n",
    "    def lazy_load_images(self):\n",
    "        \n",
    "        print(\"loading images\")\n",
    "        # load all images as one dask array - dask.array.stack(data = [],  axis = 0)\n",
    "        #files = os.listdir(self.denoised_dir)\n",
    "        #ims = [os.path.join(self.denoised_dir,file) for file in files if '16bit' in file]\n",
    "        \n",
    "        #da_ims = []\n",
    "\n",
    "        #for im in ims:\n",
    "        #    da_im = imread.imread(im, nframes = 1)\n",
    "        #    da_ims.append(da_im)\n",
    "        self.im  = da.from_zarr(os.path.join(self.denoised_dir, \"8bit.zarr\"), chunks= (5, 1000, -1, -1))\n",
    "        \n",
    "        #self.im = da.stack(da_ims)\n",
    "        \n",
    "        print(\"loading finished\")\n",
    "        \n",
    "    \n",
    "    def stim_changed(self, event):\n",
    "        print(self.volume_df.trial.unique())\n",
    "        self.stim = event\n",
    "        self.stim_subset  = self.volume_df[self.volume_df.stim == self.stim]\n",
    "        self.update_menu_choices()\n",
    "        self.load_subset()\n",
    "        print(event)\n",
    "        \n",
    "    def load_subset(self):\n",
    "        self.get_volume_subset()\n",
    "        if self.volume_subset.shape[0] > 0:\n",
    "            self.load_image()\n",
    "            self.plot_cell(self.cell)\n",
    "            self.label_stim()\n",
    "            self.plot_ephys()\n",
    "            \n",
    "        \n",
    "        \n",
    "    def update_menu_choices(self):\n",
    "        trials = self.stim_subset.trial.dropna().unique().tolist()\n",
    "        angles = self.stim_subset.angle.dropna().unique().tolist()\n",
    "        velocities = self.stim_subset.velocity.dropna().unique().tolist()\n",
    "        \n",
    "        self.angle = angles[0]\n",
    "        self.velocity = velocities[0]\n",
    "        self.trial = trials[0]\n",
    "        \n",
    "        # initiates change loop\n",
    "        self.trial_menu.choices = trials\n",
    "        self.angle_menu.choices = angles\n",
    "        self.velocity_menu.choices = velocities\n",
    "        \n",
    "        \n",
    "        print(self.angle, self.velocity, self.trial)\n",
    "        # update choices of trial, angle, velocity\n",
    "        \n",
    "        \n",
    "    def trial_changed(self, event):\n",
    "        self.trial = event\n",
    "        self.load_subset()\n",
    "        print(\"new trial {}\".format(event))\n",
    "        \n",
    "    def angle_changed(self, event):\n",
    "        self.angle = event\n",
    "        self.load_subset()\n",
    "        \n",
    "        print(\"new angle {}\".format(event))\n",
    "        \n",
    "    def velocity_changed(self, event):\n",
    "        self.velocity = event\n",
    "        self.load_subset()\n",
    "        print(\"new velocity {}\".format(event))\n",
    "        \n",
    "    def volume_df_picker_changed(self, event):\n",
    "        print(event)\n",
    "        \n",
    "        try:\n",
    "            self.volume_df_path = event\n",
    "        except:\n",
    "            self.volume_df_path = event.value\n",
    "        \n",
    "        \n",
    "        # get denoised dir\n",
    "        self.denoised_dir = os.path.dirname(self.volume_df_path)\n",
    "        \n",
    "        # load all dataframes\n",
    "        \n",
    "        self.load_volume_df(self.volume_df_path)\n",
    "        \n",
    "        # load images\n",
    "        self.lazy_load_images()\n",
    "        # load reference images, and create io template to load domain and codomain grid2worlds and register\n",
    "        self.load_overview_image()\n",
    "        self.load_h2b_reference()\n",
    "        self.create_IO_template()\n",
    "        \n",
    "        # load centre of masses and contours and apply any transforms\n",
    "        self.load_coms_df(os.path.join(self.denoised_dir, \"all_neuron_centers.h5\"))\n",
    "        self.load_con_df(os.path.join(self.denoised_dir, \"all_neuron_contours.h5\"))\n",
    "        #self.load_dff_df(os.path.join(self.denoised_dir, \"dff.h5\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.stim_changed(self.stim_menu.value)\n",
    "        \n",
    "        \n",
    "    def get_volume_subset(self):\n",
    "        print(self.stim, self.angle, self.velocity, self.trial)\n",
    "        stim_filter = self.volume_df.stim == self.stim\n",
    "        angle_filter = self.volume_df.angle == self.angle\n",
    "        velocity_filter = self.volume_df.velocity == self.velocity\n",
    "        trial_filter = self.volume_df.trial == self.trial\n",
    "        \n",
    "        self.volume_subset = self.volume_df[(stim_filter) & (angle_filter) & ( velocity_filter) & (trial_filter)]\n",
    "        \n",
    "        if self.volume_subset.shape[0] > 0:\n",
    "         # 4 seconds before\n",
    "            vols_before = int(4 * self.fr)\n",
    "            \n",
    "            self.cond_start  = self.volume_subset.nVol.iloc[0] \n",
    "            self.cond_end = self.volume_subset.nVol.iloc[-1] \n",
    "            self.first_vol = self.cond_start - vols_before\n",
    "            self.end_vol = self.cond_end + vols_before\n",
    "            self.vols = np.arange(self.first_vol, self.end_vol)\n",
    "            \n",
    "    def add_dff_widget(self):\n",
    "        \n",
    "        self.viewer1d = napari_plot.ViewerModel1D()\n",
    "        widget = QtViewer(self.viewer1d)\n",
    "        self.viewer.window.add_dock_widget(widget, area=\"bottom\", name=\"Dff Widget\")\n",
    "        self.viewer1d.axis.x_label = \"Time\"\n",
    "        self.viewer1d.axis.y_label = \"DeltaF/F\"\n",
    "        self.viewer1d.reset_view()\n",
    "        \n",
    "    def add_ephys_widget(self):\n",
    "        \n",
    "        self.viewer1d_ephys = napari_plot.ViewerModel1D()\n",
    "        widget = QtViewer(self.viewer1d_ephys)\n",
    "        self.viewer.window.add_dock_widget(widget, area=\"bottom\", name=\"Ephys Widget\", allowed_areas = [\"bottom\"], add_vertical_stretch = True)\n",
    "        self.viewer1d_ephys.axis.x_label = \"Time\"\n",
    "        self.viewer1d_ephys.axis.y_label = \"Power\"\n",
    "        self.viewer1d_ephys.reset_view()\n",
    "    \n",
    "    def clear_plot(self):\n",
    "        self.viewer1d.clear_canvas()\n",
    "        self.viewer1d_ephys.clear_canvas()\n",
    "    \n",
    "    def plot_ephys(self):\n",
    "        if self.stim != None:\n",
    "            vol_filter = self.dff_tidy.nVol.isin(self.vols)\n",
    "            cell_filter = self.dff_tidy.cell_id == self.cell\n",
    "            trial_subset = self.dff_tidy.loc[ vol_filter & cell_filter, [\"Rightconvolved\", \"Leftconvolved\"]]\n",
    "            trial_subset\n",
    "            t = np.arange(trial_subset.shape[0])/ self.fr\n",
    "            self.viewer1d_ephys.add_line(np.c_[t, trial_subset.Rightconvolved.to_numpy()], color = \"magenta\")\n",
    "            self.viewer1d_ephys.add_line(np.c_[t, trial_subset.Leftconvolved.to_numpy()], color = \"cyan\")\n",
    "            self.viewer1d_ephys.reset_view()\n",
    "        \n",
    "    def plot_cell(self, event):\n",
    "        if self.stim != None:\n",
    "            self.clear_plot()\n",
    "            # define cell event\n",
    "            # get dff info for cell\n",
    "            # get contour of cell\n",
    "            self.cell = event\n",
    "\n",
    "            stim_filter = self.dff_tidy.stim == self.stim\n",
    "            angle_filter = self.dff_tidy.angle == self.angle\n",
    "            velocity_filter = self.dff_tidy.velocity == self.velocity\n",
    "            trial_filter = self.dff_tidy.trial == self.trial\n",
    "            cell_filter = self.dff_tidy.cell_id == self.cell\n",
    "\n",
    "\n",
    "            self.dff_subset  = self.dff_tidy[(stim_filter) & (angle_filter) & (velocity_filter) & (cell_filter)]\n",
    "\n",
    "            # plot every trial but highlight current one with thicker line\n",
    "\n",
    "            for trial in self.dff_subset.trial.unique():\n",
    "                trial_subset = self.dff_subset[self.dff_subset.trial == trial]\n",
    "                trial_start = trial_subset.nVol.iloc[0]\n",
    "                trial_end = trial_subset.nVol.iloc[-1]\n",
    "                vols_before = int(4 * self.fr)\n",
    "                first_vol = trial_start - vols_before\n",
    "                last_vol = trial_end + vols_before\n",
    "                vols = np.arange(first_vol, last_vol)\n",
    "                vol_filter = self.dff_tidy.nVol.isin(vols)\n",
    "\n",
    "                plotting_subset = self.dff_tidy[cell_filter & vol_filter]\n",
    "                t = np.arange(0, plotting_subset.shape[0]/self.fr, 1/self.fr)\n",
    "\n",
    "                if trial == self.trial:\n",
    "\n",
    "                    self.viewer1d.add_line(np.c_[t, plotting_subset.dff.to_numpy()], color = \"magenta\")\n",
    "                    regions = [\n",
    "                            ([t[trial_start-first_vol], t[trial_end-first_vol]], \"vertical\"),\n",
    "                        ]\n",
    "\n",
    "                    layer = neuroviewer.viewer1d.add_region(\n",
    "                            regions,\n",
    "                            color=[\"green\"],\n",
    "                            opacity = 0.4,\n",
    "                            name = \"Stim\",\n",
    "                        )\n",
    "\n",
    "                else:\n",
    "                    self.viewer1d.add_line(np.c_[t, plotting_subset.dff.to_numpy()], name=\"trial {}\".format(trial), color=\"gray\")\n",
    "\n",
    "\n",
    "\n",
    "                self.viewer1d.reset_view()\n",
    "            \n",
    "        \n",
    "    def label_stim(self):\n",
    "        start = self.cond_start - self.first_vol\n",
    "        end = self.cond_end - self.first_vol\n",
    "        stim_duration = end - start\n",
    "\n",
    "        nframes = stim_duration\n",
    "        centre_rs = np.tile(np.array([0, 30, 30]), (4, 1))\n",
    "        centres = np.stack([centre_rs] * nframes)\n",
    "        frame_pos = np.tile(np.arange(start, end).T, (4, 1)).T\n",
    "        centres[:, :, 0] = frame_pos\n",
    "        add_array = np.array([[0, -10, -10],\n",
    "                                      [0, -10, 10],\n",
    "                                      [0, 10, 10],\n",
    "                                      [0, 10, -10]])\n",
    "\n",
    "        #define boxes by adding to centre_rs\n",
    "        boxes = centres + add_array.reshape(-1, *add_array.shape)\n",
    "        labels = [\"stim\"] * stim_duration\n",
    "        properties = {\n",
    "            'label': labels,\n",
    "\n",
    "        }\n",
    "\n",
    "        # specify the display parameters for the text\n",
    "        text_params = {\n",
    "            'text': '{label}',\n",
    "            'size': 12,\n",
    "            'color': 'green',\n",
    "            'anchor': 'upper_left',\n",
    "            'translation': [-3, 0]}\n",
    "\n",
    "        self.stim_icon.data = boxes\n",
    "        self.stim_icon.properties = properties\n",
    "        self.stim_icon.text = text_params\n",
    "        \n",
    "    def plot_all_contours(self): # slow\n",
    "        \n",
    "        #try:\n",
    "        if self.io_affine is not None:\n",
    "            io_affine = self.io_affine\n",
    "\n",
    "        elif self.grid_copy is not None:\n",
    "            io_affine = self.grid_copy\n",
    "\n",
    "        else:\n",
    "            io_affine = np.eye(4)\n",
    "\n",
    "        self.transform_contours(io_affine, self.io_grid2world, self.ref_grid2world)\n",
    "            \n",
    "        #except:\n",
    "        #    print(\"error registering contours\")\n",
    "        \n",
    "        z_index = [] \n",
    "        shapes= []\n",
    "        for cell in self.con_df_copy.cell_id.sort_values().unique():\n",
    "            subset = self.con_df_copy[self.con_df_copy.cell_id == cell].dropna()\n",
    "            contours = subset[[\"z\",\"cell_id\", \"y\", \"x\"]]\n",
    "\n",
    "            contours.cell_id = np.zeros(contours.shape[0])\n",
    "\n",
    "\n",
    "            z_index.append(subset.iloc[0, 2])\n",
    "            \n",
    "            shapes.append(np.round_(contours.to_numpy(), 2))\n",
    "            \n",
    "        \n",
    "        self.select_roi.selected_data = set(range(self.select_roi.nshapes))\n",
    "        self.select_roi.remove_selected()\n",
    "\n",
    "        self.select_roi.add(shapes,shape_type = \"polygon\", edge_width=0.4,\n",
    "                                  edge_color='white', face_color='transparent')\n",
    "        \n",
    "    \n",
    "    def roi_selected(self, event):\n",
    "        if len(self.select_roi.selected_data) > 0:\n",
    "            self.cell_ids.value = list(self.select_roi.selected_data)[0]\n",
    "            \n",
    "    def load_overview_image(self):\n",
    "        overview_dir = os.path.join(os.path.dirname(self.denoised_dir), \"overview\")\n",
    "        overview_file = [os.path.join(overview_dir, file) for file in os.listdir(overview_dir) if \"overview\" in file][0]\n",
    "        self.overview_im.data  = da.rot90(da.rot90(imread.imread(overview_file), axes = (1, 2)), axes = (1, 2))\n",
    "        \n",
    "    def load_h2b_reference(self):\n",
    "        self.reference_brain.data = da.rot90(\n",
    "                                    da.rot90(\n",
    "                                    da.flip(imread.imread(r\"Z:\\Pierce\\Elavl3-H2BRFP\\Elavl3-H2BRFP_rotated.tif\"), \n",
    "                                            axis=0), axes = (1, 2)), axes = (1, 2))\n",
    "        \n",
    "    def load_rigid_registered_overview(self):\n",
    "        # load registered whole brain\n",
    "        pass\n",
    "    \n",
    "    def load_nonrigid_registered_overview(self):\n",
    "        # load registered whole brain\n",
    "        pass\n",
    "        \n",
    "    def create_IO_template(self):\n",
    "        # load registered template IO to get rough alignment \n",
    "        self.template_orig = self.im[:, :10].max(axis= 1).compute()\n",
    "        \n",
    "        # in future create these grid2worlds using image metadata\n",
    "        self.ref_grid2world = np.array([[ 1.,    0.,         0.,          0.],\n",
    "                                         [0.,   0.01171,   0.,            0.],\n",
    "                                         [0.,   0.,         0.01171,      0.],\n",
    "                                         [0.,   0.,         0.,           1.]])\n",
    "        \n",
    "        self.io_grid2world = np.array( [[ 5.,   0.,         0.,          0.],\n",
    "                                         [0.,   0.008758,  0.,            0.],\n",
    "                                         [0.,   0.,         0.008758,     0.],\n",
    "                                         [0.,   0.,         0.,          1.]])\n",
    "        \n",
    "        affine = np.eye(4)\n",
    "        \n",
    "        \n",
    "        self.template.data = self.apply_tranform(self.ref_grid2world, self.io_grid2world, affine, self.overview_im.data, self.template_orig)\n",
    "        \n",
    "    def apply_tranform(self, ref_grid2world, im_grid2world, affine, ref, im):\n",
    "    \n",
    "        \n",
    "        affine_map = AffineMap(affine,\n",
    "                               ref.shape, ref_grid2world,\n",
    "                               im.shape, im_grid2world)\n",
    "        resampled = affine_map.transform(im)\n",
    "        \n",
    "        return resampled\n",
    "        \n",
    "        \n",
    "    def translate(self, event):\n",
    "        \n",
    "        if self.moving_grid2world is not None:\n",
    "            # manually estimate translation\n",
    "            self.x = self.translate_x.value\n",
    "            self.y = self.translate_y.value\n",
    "            self.z = self.translate_z.value\n",
    "\n",
    "            self.grid_copy = np.eye(4)\n",
    "            self.grid_copy[2, -1] += self.x # x\n",
    "            self.grid_copy[1, -1] += self.y # y\n",
    "            self.grid_copy[0, -1] += self.z # z\n",
    "            \n",
    "            if len(self.overview_im.data.shape) > 2: # if not still empty array\n",
    "                self.template.data = self.apply_tranform(self.ref_grid2world, self.moving_grid2world, self.grid_copy, self.overview_im.data, self.template_orig)\n",
    "                \n",
    "            else:\n",
    "                self.template.data = self.apply_tranform(self.ref_grid2world, self.moving_grid2world, self.grid_copy, self.reference_brain.data, self.template_orig)\n",
    "            \n",
    "            \n",
    "\n",
    "    def save_starting_affine(self):\n",
    "        #save affine transform\n",
    "        filename = self.affine_name.value\n",
    "        np.save(os.path.join(self.denoised_dir, filename), self.grid_copy)\n",
    "        \n",
    "        \n",
    "    def load_affine_matrix(self):\n",
    "        self.io_affine = np.load(os.path.join(self.denoised_dir, \"io_affine.npy\"))\n",
    "        \n",
    "    \n",
    "    def transform_coordinates(self, coordinates, affine_transform, domain_transform, codomain_transform):\n",
    "        # in shape z, y, x, 1\n",
    "        new_coords = np.zeros(coordinates.shape)\n",
    "        for coord_idx, coord in enumerate(coordinates):\n",
    "\n",
    "            new_coord = np.dot(np.linalg.inv(codomain_transform), np.dot(affine_transform, np.dot(domain_transform, coord)))\n",
    "            new_coords[coord_idx] = new_coord\n",
    "\n",
    "        return new_coords\n",
    "    \n",
    "    def transform_contours(self, io_affine, domain_grid2world, codomain_grid2world): # self.io_grid2world, self.ref_grid2world\n",
    "        self.con_df_copy = self.con_df.copy()\n",
    "        contours = self.con_df_copy.loc[:, [\"z\", \"y\", \"x\"]].to_numpy()\n",
    "        contour_coords = np.concatenate([contours, np.ones((contours.shape[0], 1))], axis= 1)\n",
    "        new_coords = self.transform_coordinates(contour_coords, io_affine, domain_grid2world, codomain_grid2world)\n",
    "        self.con_df_copy.loc[:, [\"z\", \"y\", \"x\"]] = new_coords[:, :3]\n",
    "        \n",
    "    def read_moving_im(self, event):\n",
    "        # read template image\n",
    "        # read image\n",
    "        # assign to template layer data\n",
    "        # load or create template_grid2world from image metadata\n",
    "        filename = str(self.moving_im_file.value)\n",
    "        \n",
    "        \n",
    "        if \"io\" in filename:\n",
    "            # dont rotate\n",
    "            self.moving_im = imread.imread(str(filename))\n",
    "            self.moving_grid2world = np.eye(4)\n",
    "            \n",
    "            self.moving_grid2world[0, 0] = 5\n",
    "            \n",
    "            # get x, y px2ref from image metadata\n",
    "            x, y = self.get_px2ref(filename)\n",
    "            self.moving_grid2world[1, 1] = y\n",
    "            self.moving_grid2world[2, 2] = x\n",
    "            self.moving_grid2world = np.array( [[ 5.,   0.,         0.,          0.],\n",
    "                                                 [0.,   0.008758,  0.,            0.],\n",
    "                                                 [0.,   0.,         0.008758,     0.],\n",
    "                                                 [0.,   0.,         0.,          1.]])\n",
    "        else:\n",
    "            # all other cases rotate\n",
    "            self.moving_im = da.rot90(da.rot90(imread.imread(filename), axes = (1, 2)), axes = (1, 2))\n",
    "            self.moving_grid2world = np.eye(4)\n",
    "        self.template_orig = self.moving_im.compute()\n",
    "        self.template.data = self.template_orig\n",
    "        \n",
    "        self.denoised_dir = os.path.dirname(filename)\n",
    "    \n",
    "    def read_reference_im(self, event):\n",
    "        # read reference image\n",
    "        # assign to reference layer data\n",
    "        # load or create ref_grid2world from image metadata\n",
    "        filename = str(self.reference_im_file.value)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"Elav\" in filename:\n",
    "            \n",
    "            # flip and rotate 180\n",
    "            self.ref_im = da.rot90(\n",
    "                                    da.rot90(\n",
    "                                    da.flip(imread.imread(filename), \n",
    "                                            axis=0), axes = (1, 2)), axes = (1, 2))\n",
    "            \n",
    "            self.ref_grid2world = np.array( [[ 2.,   0.,         0.,          0.],\n",
    "                                                 [0.,   1.,  0.,            0.],\n",
    "                                                 [0.,   0.,         1.,     0.],\n",
    "                                                 [0.,   0.,         0.,          1.]])\n",
    "            self.reference_brain.data = self.ref_im.compute()\n",
    "        elif \"overview\" in filename:\n",
    "            # rotate 180\n",
    "            self.ref_im = da.rot90(da.rot90(imread.imread(filename), axes = (1, 2)), axes = (1, 2))\n",
    "            \n",
    "            \n",
    "            self.ref_grid2world = np.array([[ 1.,    0.,         0.,          0.],\n",
    "                                             [0.,   0.01171,   0.,            0.],\n",
    "                                             [0.,   0.,         0.01171,      0.],\n",
    "                                             [0.,   0.,         0.,           1.]])\n",
    "            \n",
    "            self.overview_im.data = self.ref_im.compute()\n",
    "            \n",
    "    def get_px2ref(self, filename):\n",
    "        with tf.TiffFile(filename) as tif:\n",
    "            roi_artist = tif.pages[0].tags[\"Artist\"]\n",
    "            metadata = roi_artist.value.split(\"\\n\")\n",
    "            px2ref_row = [datum for datum in metadata if \"pixelToRef\" in datum][0]\n",
    "            row_idx = metadata.index(px2ref_row)\n",
    "            x = metadata[row_idx +1]\n",
    "            y = metadata[row_idx +2]\n",
    "            x_scale = float(x.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")[0])\n",
    "            y_scale = float(y.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")[1])\n",
    "            \n",
    "            return x_scale, y_scale\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8b63b3e-dec7-49d1-92d5-31b2e0bf1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer = neuro_viewer()\n",
    "# to do - try only setting the shapes at a later stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db380d4e-85cc-4466-915a-334067fd93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'io_starting_affine.npy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuroviewer.affine_name.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c2f8558-d568-433d-9e1b-fe4c4f5f30fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'io_starting_affine.npy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = neuroviewer.affine_name.value\n",
    "np.save(os.path.join(neuroviewer.denoised_dir, filename), neuroviewer.grid_copy)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d558a3-292b-4f63-886c-80a137d9dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.denoised_dir = os.path.dirname(str(neuroviewer.moving_im_file.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fa5cf56-24b1-4e7c-98e9-ae3eb27b675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neuroviewer.overview_im.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90743b6-cd55-46b4-888a-138918d108f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuroviewer.reference_brain.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2d3a944-c2dc-4abb-87f3-4cb3ba8a0f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 229.82 MiB </td>\n",
       "                        <td> 1.67 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (138, 1406, 621) </td>\n",
       "                        <td> (1, 1406, 621) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1104 Tasks </td>\n",
       "                        <td> 138 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint16 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"135\" height=\"192\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"32\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"32\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"121\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"122\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"123\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"124\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"125\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"127\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"128\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"19\" y2=\"129\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"130\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"131\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"132\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"135\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"137\" />\n",
       "  <line x1=\"29\" y1=\"19\" x2=\"29\" y2=\"139\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"30\" y2=\"140\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"141\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 32.6430368282111,22.643036828211102 32.6430368282111,142.6430368282111 10.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"63\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"64\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"65\" y2=\"2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"66\" y2=\"3\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"67\" y2=\"4\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"68\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"70\" y2=\"7\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"71\" y2=\"8\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"72\" y2=\"9\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"73\" y2=\"10\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"74\" y2=\"11\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"75\" y2=\"12\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"77\" y2=\"14\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"78\" y2=\"15\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"79\" y2=\"16\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"80\" y2=\"17\" />\n",
       "  <line x1=\"29\" y1=\"19\" x2=\"82\" y2=\"19\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"83\" y2=\"20\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"84\" y2=\"21\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"85\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"32\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"63\" y1=\"0\" x2=\"85\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 63.001422475106686,0.0 85.64445930331779,22.643036828211102 32.6430368282111,22.643036828211102\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"85\" y2=\"22\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"32\" y1=\"142\" x2=\"85\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"85\" y1=\"22\" x2=\"85\" y2=\"142\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"32.6430368282111,22.643036828211102 85.64445930331779,22.643036828211102 85.64445930331779,142.6430368282111 32.6430368282111,142.6430368282111\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"59.143748\" y=\"162.643037\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >621</text>\n",
       "  <text x=\"105.644459\" y=\"82.643037\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,105.644459,82.643037)\">1406</text>\n",
       "  <text x=\"11.321518\" y=\"151.321518\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,11.321518,151.321518)\">138</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<transpose, shape=(138, 1406, 621), dtype=uint16, chunksize=(1, 1406, 621), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuroviewer.ref_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474bd64-6767-4910-b7b1-b22f49fd92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1384a5-5e5d-4615-bfe8-2e5384218150",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = r\"Z:\\Pierce\\IOMultiSensory\\20220427\\fish1\\overview\\fish1_full_stack_overview_z1_steps250_00001.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073bd7d-28e2-4c20-9240-2c32625524f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.TiffFile(filename2) as tif:\n",
    "    roi_artist = tif.pages[0].tags[\"Artist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42562f-4224-4d49-b7f8-0b536739f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif.pages[0].tags[\"ResolutionUnit\"].value.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42495a52-0d74-45b1-afe6-ab9c9c46f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "(18874/1073741824) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c2056-0c58-4047-bcd0-a2beef3f8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif.pages[0].tags[\"XResolution\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2e7c9-024d-41b6-bd44-6b30fd0e43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(tag) for tag in tif.pages[0].tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3d6e0-0092-41ff-825c-0e1d3c55a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = tif.pages[0].tags[\"Software\"].value.split(\"\\n\")\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593927a2-a130-446e-9e94-880e7cf2a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(data.split(\"=\")[-1]) for data in metadata if \"micron\" in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80852ab2-60fd-4990-99b8-15e9513deb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_position = axes_position.replace(\"[\", \"\").replace(\"]\", \"\")[1:].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab03935-f14b-4ee3-95c5-88c316bdb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_x = float(split_position[0])\n",
    "axes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da87740-51cf-43dc-9f63-ce04a1d6def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in metadata:\n",
    "    \n",
    "    if \"SI.hFastZ.position\" in datum:\n",
    "        fastz_position = float(datum.split(\"=\")[-1])\n",
    "    \n",
    "    if \"SI.hMotors.axesPosition\" in datum:\n",
    "        axes_position = datum.split(\"=\")[-1]\n",
    "        split_position = axes_position.replace(\"[\", \"\").replace(\"]\", \"\")[1:].split(\" \")\n",
    "        axes_x = float(split_position[0])\n",
    "        axes_y = float(split_position[1])\n",
    "        axes_z = float(split_position[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "991a3d50-06d5-4ff3-9f73-8aba75d02daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_px2ref(filename):\n",
    "    with tf.TiffFile(filename) as tif:\n",
    "        roi_artist = tif.pages[0].tags[\"Artist\"]\n",
    "        metadata = roi_artist.value.split(\"\\n\")\n",
    "        px2ref_row = [datum for datum in metadata if \"pixelToRef\" in datum][0]\n",
    "        row_idx = metadata.index(px2ref_row)\n",
    "        x = metadata[row_idx +1]\n",
    "        y = metadata[row_idx +2]\n",
    "        x_scale = float(x.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")[0])\n",
    "        y_scale = float(y.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")[1])\n",
    "        return x_scale, y_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c30f0320-78a1-4e5f-b513-f2234b8c1145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01171875, 0.01171875)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_px2ref(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceab754-2b67-4ae1-b3dc-168e9ecbb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(tag) for tag in tif.pages[0].tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a7478-bc82-4080-ac84-07d7de0cc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(tag.value) for tag in tif.pages[0].tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f835d-4723-4c18-8294-ea6c0fc4eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = roi_artist.value.split(\"\\n\")\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dfb0f-a4ca-4633-8fc5-9af99beccdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_affine = np.load(os.path.join(os.path.dirname(neuroviewer.denoised_dir), \"overview\\\\affine_map.npy\"))\n",
    "ref_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055ecdb-4966-454b-90c3-888fde8956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zbrain_grid2world = np.array([[2.,    0.,     0.,    0.],\n",
    "                             [0.,     1.,    0.,    0.],\n",
    "                             [0.,     0.,     1.,   0.],\n",
    "                             [0.,     0.,     0.,   1.]])\n",
    "\n",
    "\n",
    "ref_grid2zbrain = np.array([[1.,   0.,      0.,    0.],\n",
    "                             [0.,     1.,     0.,    200.],\n",
    "                             [0.,     0.,     1.,    -200.],\n",
    "                             [0.,     0.,     0.,     1.]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb3b6d-9a56-4e38-b054-a28d53ad1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ref = neuroviewer.apply_tranform(zbrain_grid2world, ref_grid2zbrain, ref_affine, neuroviewer.reference_brain.data, neuroviewer.overview_im.data.compute())\n",
    "transformed_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bb391-19d6-4424-8c86-162416ed10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.overview_im.data = transformed_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07c87f-fb8a-434e-8e62-70e5c7d38069",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.reference_brain.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ebe50-c100-487f-beb8-b67c57eaf553",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.overview_im.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599caaba-7600-4c22-9e6d-c108fd04d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Z:\\Pierce\\IOMultiSensory\\20220427\\fish1\\overview\\affine_map.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d816c48-fa03-41a0-9a6e-1fdb1c5b7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291f9fe-9eb6-487f-8960-35cf51888bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "dims = neuroviewer.template.data.shape[1:]\n",
    "patches = []\n",
    "\n",
    "for cell in neuroviewer.con_df.cell_id.unique():\n",
    "        contour = neuroviewer.con_df.loc[neuroviewer.con_df.cell_id == cell, [\"x\", \"y\"]].to_numpy()\n",
    "        p = Polygon(contour, closed=True, edgecolor = 'white', linewidth = 0.2)\n",
    "\n",
    "        patches.append(p)\n",
    "ax1.imshow(np.zeros((dims[1], dims[0])), cmap = \"gray\")\n",
    "collection = PatchCollection(patches, alpha=0.9)\n",
    "collection.set_edgecolors(\"gray\")\n",
    "collection.set_linewidth(0.4)\n",
    "\n",
    "\n",
    "ax1.add_collection(collection)\n",
    "\n",
    "patches = []\n",
    "\n",
    "for cell in neuroviewer.con_df_copy.cell_id.unique():\n",
    "        contour = neuroviewer.con_df_copy.loc[neuroviewer.con_df_copy.cell_id == cell, [\"x\", \"y\"]].to_numpy()\n",
    "        p = Polygon(contour, closed=True, edgecolor = 'white', linewidth = 0.2)\n",
    "\n",
    "        patches.append(p)\n",
    "ax1.imshow(np.zeros((dims[1], dims[0])), cmap = \"gray\")\n",
    "collection = PatchCollection(patches, alpha=0.9)\n",
    "collection.set_edgecolors(\"magenta\")\n",
    "collection.set_linewidth(0.4)\n",
    "\n",
    "\n",
    "ax1.add_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0846e3-2fbd-4e44-88fe-e7e8cde32f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#io_affine = np.eye(4)\n",
    "#io_affine[1, -1] = 5\n",
    "\n",
    "# seems to use the absolute version of the matrix\n",
    "io_affine = np.abs(np.load(os.path.join(neuroviewer.denoised_dir, \"io_affine.npy\")))\n",
    "neuroviewer.transform_contours(io_affine, neuroviewer.io_grid2world, neuroviewer.ref_grid2world)\n",
    "io_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d29dd-1a76-48f6-aaa3-f10dd92145bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "dims = neuroviewer.template.data.shape[1:]\n",
    "patches = []\n",
    "\n",
    "for cell in neuroviewer.con_df.cell_id.unique():\n",
    "        contour = neuroviewer.con_df.loc[neuroviewer.con_df.cell_id == cell, [\"x\", \"y\"]].to_numpy()\n",
    "        p = Polygon(contour, closed=True, edgecolor = 'white', linewidth = 0.2)\n",
    "\n",
    "        patches.append(p)\n",
    "ax1.imshow(np.zeros((dims[1], dims[0])), cmap = \"gray\")\n",
    "collection = PatchCollection(patches, alpha=0.9)\n",
    "collection.set_edgecolors(\"gray\")\n",
    "collection.set_linewidth(0.4)\n",
    "\n",
    "\n",
    "ax1.add_collection(collection)\n",
    "\n",
    "patches = []\n",
    "\n",
    "for cell in neuroviewer.con_df_copy.cell_id.unique():\n",
    "        contour = neuroviewer.con_df_copy.loc[neuroviewer.con_df_copy.cell_id == cell, [\"x\", \"y\"]].to_numpy()\n",
    "        p = Polygon(contour, closed=True, edgecolor = 'white', linewidth = 0.2)\n",
    "\n",
    "        patches.append(p)\n",
    "ax1.imshow(np.zeros((dims[1], dims[0])), cmap = \"gray\")\n",
    "collection = PatchCollection(patches, alpha=0.9)\n",
    "collection.set_edgecolors(\"magenta\")\n",
    "collection.set_linewidth(0.4)\n",
    "\n",
    "\n",
    "ax1.add_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cdaca-b57a-425c-b9b8-e1be1d18851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.load_dff_df(r\"C:\\Users\\pierc\\Desktop\\dff.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebc946-2161-4535-aaac-399f1e180613",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.create_IO_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd09610-365a-48a2-9f43-91822b73ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(neuroviewer.denoised_dir, \"io_starting_affine.npy\"), neuroviewer.grid_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb55fa-ade0-4c1c-98ad-367c96440930",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.plot_all_contours()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4792148-1329-40b4-a208-d0bc0a936cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.selected_data = set(range(neuroviewer.select_roi.nshapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f78d2-5fed-4f8a-b293-1b5c4ea84558",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.nshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c8da9-7c6f-4648-8d69-28c575b97916",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.con_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207545e1-21a1-47f2-9ebe-3c668b15e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if neuroviewer.io_affine is not None:\n",
    "    io_affine = neuroviewer.io_affine\n",
    "\n",
    "elif neuroviewer.grid_copy is not None:\n",
    "    io_affine = neuroviewer.grid_copy\n",
    "\n",
    "else:\n",
    "    io_affine = np.eye(4)\n",
    "\n",
    "io_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bca017-3487-4e84-9b2d-9ef6fafdaa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_affine[1, -1] = -1\n",
    "io_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6007eb-975c-42e4-9459-a6145fd6092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_affine = np.abs(io_affine)\n",
    "io_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62c220-1637-46a9-95f1-7b72095d826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0083e40-316b-4b2d-8ded-7e55f9ec8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round_(io_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929e15e-928c-4823-bff7-212df0f88763",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.transform_contours(io_affine, neuroviewer.io_grid2world, neuroviewer.io_grid2world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13902b-90b8-4d1b-9b07-ecc674048a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round_(neuroviewer.con_df_copy[neuroviewer.con_df_copy.cell_id == 0].to_numpy(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95350230-7c3e-43f5-b5d5-ba698f3b4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.con_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c94f7-066e-4e7d-b64c-34854a36029d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e761642-9151-4763-b726-734357c9bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes= []\n",
    "\n",
    "for cell in neuroviewer.con_df_copy.cell_id.sort_values().unique():\n",
    "    subset = neuroviewer.con_df_copy[neuroviewer.con_df_copy.cell_id == cell].dropna()\n",
    "    contours = subset[[\"z\",\"cell_id\", \"y\", \"x\"]]\n",
    "\n",
    "    contours.cell_id = np.zeros(contours.shape[0])\n",
    "\n",
    "    shapes.append(contours.to_numpy())\n",
    "\n",
    "\n",
    "    \n",
    "#neuroviewer.select_roi.selected_data = set(range(neuroviewer.select_roi.nshapes))\n",
    "#neuroviewer.select_roi.remove_selected()\n",
    "neuroviewer.select_roi.add(shapes, shape_type = \"polygon\", edge_width=0.4,\n",
    "                          edge_color='white', face_color='transparent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0abf5-7354-4b8a-a16f-199ede3bd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc34b6-24b3-4683-a3bf-bef1505213be",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.nshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390a52c-9b63-493c-9e4d-de5fbed71aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e781e80-bcc6-4446-9c2b-236e32f8c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.grid_copy, neuroviewer.io_grid2world, neuroviewer.ref_grid2world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870468e-96f5-4d8f-938d-ee15dd1b8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.template_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f5dc6-1cc2-48c5-968e-6037ec44e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(self.denoised_dir, \"io_starting_affine.npy\"), self.grid_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bea849-fbaa-4b5e-a2f9-8f3265e135e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.edgewidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25f603-f2f1-4941-8324-889e9cbec703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coordinates(coordinates, affine_transform, domain_transform, codomain_transform):\n",
    "    # in shape z, y, x, 1\n",
    "    new_coords = np.zeros(coordinates.shape)\n",
    "    for coord_idx, coord in enumerate(coordinates):\n",
    "        \n",
    "        new_coord = np.dot(np.linalg.inv(codomain_transform), np.dot(affine_transform, np.dot(domain_transform, coord)))\n",
    "        new_coords[coord_idx] = new_coord\n",
    "        \n",
    "    return new_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8def37-d44d-4c71-abe0-ddce9d535ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33554a33-e24f-4b86-9e32-1217dc3cc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "transform_coordinates(contour_coords, neuroviewer.grid_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2fd30-7367-4194-93a1-f3086f5ab710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "transform_coordinates(contour_coords, neuroviewer.grid_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74382a-eba2-4bc7-8731-7f7b70254833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con_df_copy = neuroviewer.con_df.copy()\n",
    "new_coords = transform_coordinates(contour_coords, io_affine, neuroviewer.ref_grid2world, neuroviewer.io_grid2world)\n",
    "con_df_copy.loc[:, [\"z\", \"y\", \"x\"]] = new_coords[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047a292-a377-4313-b264-4e28b0f17e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88688f-c95e-4ced-9a3a-28a8755df9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to grid\n",
    "io_affine = np.load(os.path.join(neuroviewer.denoised_dir, \"IO_affine.npy\"))\n",
    "io_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f398e-c790-485d-9f7a-bfc1d3feea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.template.data.shape #z,  y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c11788-26d1-4465-b4ed-f53b08faee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_affine2 = np.eye(4)\n",
    "io_affine2[:, -1] = io_affine[:, -1]\n",
    "io_affine2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5fb71-b17f-4be7-85e6-059620fe016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_grid2world = np.eye(4)\n",
    "io_grid2world[:, :-1] = neuroviewer.io_grid2world[:, :-1]\n",
    "io_grid2world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2d1b0-e959-4fe0-addb-fb44f2f0d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10b260-36fb-4764-a44f-a3b57f9e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.ref_grid2world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4047e89-b156-45e6-92d6-4efaec8b4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_matrix = io_grid2world @ (io_affine2@neuroviewer.ref_grid2world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98446b1c-4ff5-49a0-9814-c23e4436df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb58da-01c7-4612-a871-6333f3f48152",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.con_df.head(), con_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7cbb4f-fc81-4593-8604-76d4b7e2a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7af23-59fb-4350-8a28-82573d8a40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.grid_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca79a0-c557-4390-861a-8ccdd6d9810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tranform(ref_grid2world, im_grid2world, ref, im):\n",
    "    \n",
    "        \n",
    "        identity = np.eye(4)\n",
    "        affine_map = AffineMap(identity,\n",
    "                               ref.shape, ref_grid2world,\n",
    "                               im.shape, im_grid2world)\n",
    "        resampled = affine_map.transform(im)\n",
    "        \n",
    "        return resampled, affine_map.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fad7ce-0b81-40a6-827b-2c11ec7b6fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d2046-7ae8-47b8-b00e-be0760c32f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.overview_im.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3ef9b-08d5-4681-86b0-2b74fd9ff24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.template_orig = neuroviewer.im[:, :1000].max(axis= 1).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab7315-e956-43ed-9430-9e934a037d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.template_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f59d0a-d201-4ba2-ba18-8c656fd030ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_tranform(neuroviewer.ref_grid2world, neuroviewer.io_grid2world, neuroviewer.overview_im.data, neuroviewer.template_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509c22c-1a21-4db0-b46e-3d1cab4c4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.plot_cell(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3626865-aa57-4a79-9c90-b43f5dd72a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_dir = os.path.join(os.path.dirname(neuroviewer.denoised_dir), \"overview\")\n",
    "overview_file = [os.path.join(overview_dir, file) for file in os.listdir(overview_dir)][0]\n",
    "neuroviewer.overview_im  = imread.imread(overview_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437fd92-96da-4f0f-a0ff-3c30c004eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain = neuroviewer.reference_brain.data.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b670c-1d3b-4571-a516-6d5e4a576b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain3 = neuroviewer.reference_brain.data.flip(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba118575-4bac-4c22-8236-3957a2cc499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain3 = da.flip(neuroviewer.reference_brain.data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be790d-ad46-47fe-98e8-f773e795ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain2 = ref_brain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354d14e-f711-4411-a290-be8bb8ab5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69f25d-ae1e-4fc2-9905-2150e8b658ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brain2 = np.flip(ref_brain2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25389648-3359-4116-84da-7fc3cca60eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols = 2)\n",
    "ax1.imshow(ref_brain3[0])\n",
    "ax2.imshow(ref_brain3[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a70b8-1c2a-4825-8a40-25f979eec262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955a3f0-80c1-4c67-9592-43d821f40881",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(neuroviewer.reference_brain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2501024-6759-48f4-8f40-936d4c5e29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.overview_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfce6e-ad43-4557-bb0b-72b68da0ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_filter = neuroviewer.dff_tidy.nVol.isin(neuroviewer.vols)\n",
    "cell_filter = neuroviewer.dff_tidy.cell_id == neuroviewer.cell\n",
    "trial_subset = neuroviewer.dff_tidy.loc[ vol_filter & cell_filter, [\"Rightconvolved\", \"Leftconvolved\"]]\n",
    "trial_subset\n",
    "t = np.arange(trial_subset.shape[0])/ neuroviewer.fr\n",
    "neuroviewer.viewer1d_ephys.add_line(np.c_[t, trial_subset.Rightconvolved.to_numpy()], color = \"magenta\")\n",
    "neuroviewer.viewer1d_ephys.add_line(np.c_[t, trial_subset.Leftconvolved.to_numpy()], color = \"cyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c3b40-2996-43f4-abb1-53379bfd47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.events.highlight.connect(highlight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f821c-1e6e-4e4a-bd4e-7c03008e6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(event):\n",
    "    neuroviewer.cell_ids.value = list(neuroviewer.select_roi.selected_data)[0]\n",
    "    print(neuroviewer.select_roi.selected_data)\n",
    "    neuroviewer.select_roi.current_edge_color = \"green\"\n",
    "    neuroviewer.select_roi.current_edge_width = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0977ce-8b6d-4d4b-930e-6af5306ead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.cell_ids.value = list(neuroviewer.select_roi.selected_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c0653-e79b-47d4-91dd-fcbc4aafb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "neuroviewer.im[:, 100:120].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c150fa-b3c0-443e-8372-9aff24e64416",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(neuroviewer.denoised_dir)\n",
    "ims = [os.path.join(neuroviewer.denoised_dir,file) for file in files if '16bit' in file]\n",
    "\n",
    "da_ims = []\n",
    "\n",
    "for im in ims:\n",
    "    da_im = imread.imread(im)\n",
    "    da_ims.append(da_im)\n",
    "\n",
    "neuroviewer.im = da.stack(da_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1af7ff-0ac1-4104-ab05-dd8195ea6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_im = da.from_zarr(os.path.join(neuroviewer.denoised_dir, \"8bit.zarr\"), chunks= (5, 1000, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f0eb5-a3ee-4fee-9343-cb5e81656771",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ef940-0e5a-4a9f-811b-28280facb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afb4ef-0040-4cfd-ac0e-e9d8ddf44a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.im_subset.contrast_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8f8d2-b095-40de-923e-b54f1e9eb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.im_subset.data = neuroviewer.im[:, neuroviewer.first_vol: neuroviewer.end_vol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf608ff-bd08-40ce-bf91-cdbbb27b04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccac042-8d0d-469b-83ae-5fef385119df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "da_im[:, neuroviewer.first_vol : neuroviewer.end_vol ].compute()\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1a713-f8ef-421b-857a-51fab63d1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_im[:, neuroviewer.first_vol : neuroviewer.end_vol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11397d17-4797-4c4a-8fd4-6964d0bd072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2a3f4-6a6c-4f81-a7da-2eacaebe617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(da_im[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb7803-b87a-415f-a9a2-0a042fa8967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(neuroviewer.denoised_dir)\n",
    "im_path = [os.path.join(neuroviewer.denoised_dir,file) for file in files if '16bit' in file][0]\n",
    "\n",
    "\n",
    "\n",
    "neuroviewer.im = imread.imread(im_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda83db-a682-4113-9010-9bb29164638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.im # file saved incorrectly - save as 16 bit instead and in big tiff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7e17a-1541-46f2-99ac-3c18ec7c973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_rs = np.tile(np.array([0, 30, 30]), (4, 1))\n",
    "centres = np.stack([centre_rs] * nframes)\n",
    "frame_pos = np.tile(np.arange(start, end).T, (4, 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbeaaa-cf85-4964-955c-7f208a9b9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.volume_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee9d52-4c08-41b1-9770-8a753f57eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through cells get x, y contour for each #\n",
    "# add first axis for volumes\n",
    "# get z_index\n",
    "start = neuroviewer.first_vol\n",
    "end = neuroviewer.end_vol\n",
    "nframes = end - start\n",
    "\n",
    "\n",
    "z_index = [] \n",
    "shapes= []\n",
    "for cell in neuroviewer.con_df.cell_id.unique():\n",
    "    subset = neuroviewer.con_df[neuroviewer.con_df.cell_id == cell].dropna()\n",
    "    contours = subset[[\"z\",\"cell_id\", \"y\", \"x\"]]\n",
    "    \n",
    "    contours.cell_id = np.zeros(contours.shape[0])\n",
    "\n",
    "    \n",
    "    z_index.append(subset.iloc[0, 2])\n",
    "    shapes.append(contours.to_numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3e2d8-1d90-4e7c-9caf-df08ad0ad8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z_index), len(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2dd76-8875-482b-9d54-fca9f77e3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.viewer.add_shapes([cell_roi], shape_type='polygon', edge_width=0.2,\n",
    "                          edge_color='white', face_color='transparent', ndim = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b16aee-c4ab-4f27-bd56-87e1f646975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi = neuroviewer.viewer.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17988815-4eb3-49c0-8c2f-4be12ed55b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.viewer.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babd6ad-2293-43f9-8efc-3a8582c6b790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7b7b4-18e0-4e7c-bfdc-31c1754c2e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389a102-666c-4086-8be7-ae175f67fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360a519-4d95-4219-bddd-999289e5f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9d3db-0e98-4661-9580-557b04701873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35818f9d-59bd-4068-9c29-c283390aa281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ca61e-e0a3-4359-b58c-bcc84a01261e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40694e-beac-455f-9edd-d0bcf508906b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94233a96-e1e1-49ce-8755-708463d43659",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.add(cell_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c6709-6b14-4305-ac73-9e84ade537ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17122b6-cd4d-489c-9a97-ae39b3e2da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e617914-33c3-4917-983f-c334a1bb9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.select_roi.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43810073-36d3-48bb-984d-67b332b7e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#neuroviewer.all_rois.data = shapes\n",
    "#neuroviewer.all_rois.edge_color = \"white\"\n",
    "#neuroviewer.all_rois.face_color = \"transparent\"\n",
    "\n",
    "neuroviewer.viewer.add_shapes(shapes, shape_type='polygon', edge_width=0.2,\n",
    "                          edge_color='white', face_color='transparent', z_index = z_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e0a58-6966-402a-aea3-7ec7dcd142f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stim_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fac039-657b-4c74-a33d-3104a5bd2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start =12\n",
    "end = 24\n",
    "stim_duration = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50cff4-16f6-463a-81ae-4774f09ffef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6c9a8-926e-4b57-90e0-78d367f43760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7d69c-27e1-4136-b557-68bd846d1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = neuroviewer.cond_start - neuroviewer.first_vol\n",
    "end = neuroviewer.cond_end - neuroviewer.first_vol\n",
    "stim_duration = end - start\n",
    "\n",
    "nframes = stim_duration\n",
    "centre_rs = np.tile(np.array([0, 30, 30]), (4, 1))\n",
    "centres = np.stack([centre_rs] * nframes)\n",
    "frame_pos = np.tile(np.arange(start, end).T, (4, 1)).T\n",
    "centres[:, :, 0] = frame_pos\n",
    "add_array = np.array([[0, -10, -10],\n",
    "                              [0, -10, 10],\n",
    "                              [0, 10, 10],\n",
    "                              [0, 10, -10]])\n",
    "\n",
    "#define boxes by adding to centre_rs\n",
    "boxes = centres + add_array.reshape(-1, *add_array.shape)\n",
    "labels = [\"stim\"] * stim_duration\n",
    "properties = {\n",
    "    'label': labels,\n",
    "\n",
    "}\n",
    "\n",
    "# specify the display parameters for the text\n",
    "text_params = {\n",
    "    'text': 'label: {label}',\n",
    "    'size': 12,\n",
    "    'color': 'green',\n",
    "    'anchor': 'upper_left',\n",
    "    'translation': [-3, 0]}\n",
    "\n",
    "neuroviewer.stim_icon.data = boxes\n",
    "neuroviewer.stim_icon.properties = properties\n",
    "neuroviewer.stim_icon.text = text_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e01ad-cde4-4130-a376-91fe94e25866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1e77a-32d3-4cb2-98ab-88202e9c2a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883c964-82bf-4fb2-b9b5-9647e40e273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.stim_icon.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c18264-e99b-40fa-b4ad-7dfa51c9cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_hdf(r\"C:\\Users\\pierc\\Desktop\\dff.h5\")\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d54816-00de-4b44-84a8-5bf747e2f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.dff_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c852c-d965-4b4f-8065-efa121025bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_filter = neuroviewer.dff_tidy.stim == neuroviewer.stim\n",
    "angle_filter = neuroviewer.dff_tidy.angle == neuroviewer.angle\n",
    "velocity_filter = neuroviewer.dff_tidy.velocity == neuroviewer.velocity\n",
    "trial_filter = neuroviewer.dff_tidy.trial == neuroviewer.trial\n",
    "cell_filter = neuroviewer.dff_tidy.cell_id == neuroviewer.cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c07176-d509-4fc4-a392-3d8445c730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_df = neuroviewer.dff_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15157603-61c7-44dd-84ed-550b7e3a7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neuroviewer.dff_tidy == dff_df\n",
    "vol_filter = neuroviewer.dff_tidy.nVol.isin(neuroviewer.vols)\n",
    "vol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139c806-e6c7-4bb1-afc9-d1c351f02ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\n",
    "    ([0, 1], \"vertical\"),\n",
    "]\n",
    "\n",
    "layer = neuroviewer.viewer1d.add_region(\n",
    "    regions,\n",
    "    color=[white],\n",
    "    opacity = 0.5,\n",
    "    name = \"Stim\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a9571-0408-4c89-82a1-755743237e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.dff_subset = neuroviewer.dff_tidy[stim_filter & angle_filter & velocity_filter & cell_filter]\n",
    "neuroviewer.dff_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14b5a9-2ee3-4faa-b25b-5330182ab72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.dff_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8256ff-2c02-42ee-9763-1371326c0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, plotting_subset.shape[0]/neuroviewer.fr, 1/neuroviewer.fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780b1cd-1215-463f-81f5-10a9906ab004",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6dcbc-6606-491c-aec8-64472d06151b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f1d38-a5e5-4591-97b6-90dc2f858d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6c0a0-327d-4fef-af4d-8f9f109c5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in neuroviewer.dff_subset.trial.unique():\n",
    "    trial_subset = neuroviewer.dff_subset[neuroviewer.dff_subset.trial == trial]\n",
    "    trial_start = trial_subset.nVol.iloc[0]\n",
    "    trial_end = trial_subset.nVol.iloc[-1]\n",
    "    vols_before = int(4 * neuroviewer.fr)\n",
    "    first_vol = trial_start - vols_before\n",
    "    last_vol = trial_end + vols_before\n",
    "    vols = np.arange(first_vol, last_vol)\n",
    "    vol_filter = neuroviewer.dff_tidy.nVol.isin(vols)\n",
    "    \n",
    "    plotting_subset = neuroviewer.dff_tidy[cell_filter & vol_filter]\n",
    "    t = np.arange(0, plotting_subset.shape[0]/neuroviewer.fr, 1/neuroviewer.fr)\n",
    "\n",
    "    if trial == neuroviewer.trial:\n",
    "        \n",
    "        neuroviewer.viewer1d.add_line(np.c_[t, plotting_subset.dff.to_numpy()], color = \"magenta\")\n",
    "\n",
    "    else:\n",
    "        neuroviewer.viewer1d.add_line(np.c_[t, plotting_subset.dff.to_numpy()], name=\"trial {}\".format(trial), color=\"gray\")\n",
    "        \n",
    "    neuroviewer.viewer1d.reset_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe15de-400a-4a87-ba5e-acaf6f3920ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_subset.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0866a02-043a-4986-803d-faad3cac6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_start = trial_subset.nVol.iloc[0]\n",
    "trial_end = trial_subset.nVol.iloc[-1]\n",
    "vols_before = int(4 * neuroviewer.fr)\n",
    "first_vol = trial_start - vols_before\n",
    "last_vol = trial_end + vols_before\n",
    "vols = np.arange(first_vol, last_vol)\n",
    "vol_filter = neuroviewer.dff_tidy.nVol.isin(vols)\n",
    "\n",
    "plotting_subset = neuroviewer.dff_tidy[cell_filter & vol_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caccc8d-c981-4a46-9ab2-7fd7a308272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd42f04-935f-4b2f-8674-35f2bd16386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[trial_subset.timebyepoch.to_numpy(), trial_subset.dff.to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debdd729-be16-4862-a7e6-7ff060387727",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_subset.timebyepoch.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8771f03-015f-4242-9f14-9e925caf18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_subset.dff.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfce88-68a0-4e74-ad98-319cbd25ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.velocity = 1.0\n",
    "\n",
    "stim_filter = neuroviewer.volume_df.stim == neuroviewer.stim\n",
    "angle_filter = neuroviewer.volume_df.angle == neuroviewer.angle\n",
    "velocity_filter = neuroviewer.volume_df.velocity == neuroviewer.velocity\n",
    "trial_filter = neuroviewer.volume_df.trial == neuroviewer.trial\n",
    "\n",
    "neuroviewer.volume_subset = neuroviewer.volume_df[(stim_filter) & (angle_filter) & ( velocity_filter) & (trial_filter)]\n",
    "neuroviewer.vols = neuroviewer.volume_subset.nVol\n",
    "neuroviewer.vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279051c-c520-4d00-85ab-e94d0afd7fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599262a-4cd3-4fd4-be07-e3aa2c404a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.trial = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac562684-951a-4a46-816a-0284dcb9ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.volume_df[(neuroviewer.volume_df.stim == self.stim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e2f16-e7f2-49e8-8745-58167a4ed3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_df = pd.read_hdf(os.path.join(neuroviewer.denoised_dir, \"dff.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c48a6-3937-49ac-8a78-18263841f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_df.set_index(\"cell_id\", inplace = True)\n",
    "dff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13e032-12f1-40ed-8603-9e785ee5ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.dff_tidy.T.to_hdf(os.path.join(neuroviewer.denoised_dir, \"dff_test.h5\"), \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048030b-adf1-4133-9db0-63d89b5cacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.dff_tidy.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02ad04-5f3a-4018-9d3e-b52f426900c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.load_dff_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6800da-ee1c-43ee-abc4-d5a127ae3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurovi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c324f44-49e0-4b83-828d-c013623a5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.im\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce80d97-3614-478a-9150-098ae40c8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer = napari.Viewer()\n",
    "\n",
    "\n",
    "\n",
    "viewer1d = napari_plot.ViewerModel1D()\n",
    "widget = QtViewer(viewer1d)\n",
    "viewer.window.add_dock_widget(widget, area=\"bottom\", name=\"Line Widget\")\n",
    "\n",
    "# example data\n",
    "x = np.arange(0.1, 4, 0.1)\n",
    "y1 = np.exp(-1.0 * x)\n",
    "y2 = np.exp(-0.5 * x)\n",
    "\n",
    "# example variable error bar values\n",
    "y1err = 0.1 + 0.1 * np.sqrt(x)\n",
    "y2err = 0.1 + 0.1 * np.sqrt(x / 2)\n",
    "\n",
    "\n",
    "viewer1d.add_line(np.c_[x, y1], name=\"Line 1\", color=\"lightblue\")\n",
    "viewer1d.add_centroids(\n",
    "    np.c_[x, y1 - y1err, y1 + y1err], orientation=\"vertical\", color=\"lightblue\", opacity=0.5, name=\"Line 1 (errors)\"\n",
    ")\n",
    "viewer1d.add_line(np.c_[x, y2], name=\"Line 2\", color=\"orange\")\n",
    "viewer1d.add_centroids(\n",
    "    np.c_[x, y2 - y2err, y2 + y2err], orientation=\"vertical\", color=\"orange\", opacity=0.5, name=\"Line 2 (errors)\"\n",
    ")\n",
    "viewer1d.camera.extent = (-0.1, 4.1, 1.0, -0.3)\n",
    "viewer1d.axis.x_label = \"\"\n",
    "viewer1d.axis.y_label = \"\"\n",
    "viewer1d.reset_view()\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501bf7c-9a3e-4db8-89b1-bfc835616c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroviewer.add_dff_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67fe79-048f-466c-a03f-49d01c9cd02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
